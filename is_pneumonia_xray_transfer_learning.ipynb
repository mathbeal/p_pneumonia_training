{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources:\n",
    "- https://keras.io/applications/#inceptionv3\n",
    "- https://www.tensorflow.org/hub/tutorials/image_retraining\n",
    "- https://www.kaggle.com/learn/deep-learning\n",
    "- https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub\n",
    "- https://towardsdatascience.com/deep-learning-with-tensorflow-part-2-image-classification-58fcdffa7b84\n",
    "- https://medium.com/google-developer-experts/building-robust-production-ready-deep-learning-vision-models-in-minutes-acd716f6450a\n",
    "- https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks\n",
    "\n",
    "- https://github.com/anjanatiha/Pneumonia-Detection-from-Chest-X-Ray-Images-with-Deep-Learning/blob/master/code/Detection%20of%20Pneumonia%20from%20Chest%20X-Ray%20Images%201.0.0.3.ipynb\n",
    "- https://github.com/FlorianWoelki/pneumonia_detection/blob/master/pneumonia_detection.ipynb\n",
    "- https://github.com/Dexter1618/MMWML/blob/master/Week04/Pneumonia_Detection_Transfer_Learning.ipynb\n",
    "\n",
    "\n",
    "# Concepts:\n",
    " - Transfer learning: Modern image recognition models have millions of parameters.Training them from scratch requires a lot of labeled training data and a lot of computing power (hundreds of GPU-hours or more). Transfer learning is a technique that shortcuts much of this by taking a piece of a model that has already been trained on a related task and reusing it in a new model.\n",
    " - ImageDataGenerator().flow_from_directory(directory): Takes the path to a directory, and generates batches of augmented/normalized data. Yields batches indefinitely, in an infinite loop.\n",
    " - Relu : Following each convolution operation, the CNN applies a Rectified Linear Unit (ReLU) transformation to the convolved feature, in order to introduce nonlinearity into the model. The ReLU function, , returns x for all values of x > 0, and returns 0 for all values of x â‰¤ 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "# Load files\n",
    "# Use ImageNet into InceptionV3 model\n",
    "# Transfer learning into new model oriented for xray pneumonia prediction.\n",
    "# Train only the part of the new model\n",
    "# Make Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\envs\\PythonCPU\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.9448173 , 0.67303226])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_image_data_config(kind, path):\n",
    "    \n",
    "    assert kind in ('train', 'test', 'valid'), f'unknown kind: {kind}'\n",
    "\n",
    "    image_data_gen_config = {\n",
    "        'rescale': 1./255.,\n",
    "        'width_shift_range':0.1,\n",
    "        'height_shift_range':0.1,\n",
    "        'shear_range':0.2,\n",
    "        'zoom_range':0.2,\n",
    "        'horizontal_flip':True,\n",
    "    }\n",
    "\n",
    "    flow_from_dir_config = {\n",
    "        'target_size': (150, 150),\n",
    "        'batch_size': 32,\n",
    "        'class_mode': 'categorical',\n",
    "        'color_mode': 'rgb',\n",
    "        'shuffle': True,\n",
    "        'seed': None,\n",
    "        'interpolation': 'nearest',\n",
    "    }\n",
    "\n",
    "    if kind == 'train':\n",
    "        return image_data_gen_config, flow_from_dir_config\n",
    "\n",
    "    # test, valid\n",
    "    img_tp = image_data_gen_config.copy()\n",
    "    wanted = ('rescale', )\n",
    "    image_data_gen_config = dict((k,v) for k,v in img_tp.items() if k in wanted)\n",
    "\n",
    "    #if kind == 'valid':\n",
    "    #    flow_from_dir_config['batch_size'] = 1\n",
    "    \n",
    "    flow_from_dir_config['shuffle'] = False\n",
    "    return image_data_gen_config, flow_from_dir_config\n",
    "\n",
    "\n",
    "class XRayData:\n",
    "    \n",
    "    @property\n",
    "    def train_generator(self):\n",
    "        return self._get_or_set('train_generator')\n",
    "    \n",
    "    @property\n",
    "    def test_generator(self):\n",
    "        return self._get_or_set('test_generator')\n",
    "    \n",
    "    @property\n",
    "    def valid_generator(self):\n",
    "        return self._get_or_set('valid_generator')\n",
    "\n",
    "    @property\n",
    "    def train_class_weights(self):\n",
    "        return self._get_or_set('train_class_weights')\n",
    "    \n",
    "    def _set_train_generator(self, path='./data/input/train'):\n",
    "        config1, config2 = get_image_data_config('train', path)\n",
    "        tp = ImageDataGenerator(**config1)\n",
    "        self._train_generator = tp.flow_from_directory(path, **config2)\n",
    "    \n",
    "    def _set_test_generator(self, path='./data/input/test'):\n",
    "        config1, config2 = get_image_data_config('train', path)\n",
    "        tp = ImageDataGenerator(**config1)\n",
    "        self._test_generator = tp.flow_from_directory(path, **config2)\n",
    "        \n",
    "    def _set_valid_generator(self, path='./data/input/val'):\n",
    "        config1, config2 = get_image_data_config('valid', path)\n",
    "        tp = ImageDataGenerator(**config1)\n",
    "        self._valid_generator = tp.flow_from_directory(path, **config2)\n",
    "    \n",
    "    def _set_train_class_weights(self):\n",
    "        from sklearn.utils.class_weight import compute_class_weight\n",
    "        from numpy import unique\n",
    "        y = self.train_generator.classes\n",
    "        labels = unique(y)\n",
    "        self._train_class_weights = compute_class_weight(\"balanced\", labels, y)\n",
    "    \n",
    "    def _get_or_set(self, attr):\n",
    "        attr = f'_{attr}'\n",
    "        if not hasattr(self, attr):\n",
    "            getattr(self, f'_set{attr}')()\n",
    "        return getattr(self, attr)\n",
    "    \n",
    "\n",
    "xraydata = XRayData()\n",
    "xraydata.train_generator\n",
    "xraydata.test_generator\n",
    "xraydata.valid_generator\n",
    "xraydata.train_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.layers import Dropout, GlobalAveragePooling2D, BatchNormalization, Dense\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\envs\\PythonCPU\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 3, 3, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,907,106\n",
      "Trainable params: 2,102,274\n",
      "Non-trainable params: 21,804,832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "base_model = InceptionV3(weights = \"imagenet\", include_top = False, input_shape = (150, 150, 3))\n",
    "base_model.trainable = False    # Transfer learning is here (not retrained model)\n",
    "\n",
    "# extra part: specific to pneumonia xray training.\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='softmax')) # 2 : num of classes\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTED at : 2019-09-28 20:08:05.386273\n",
      "Epoch 1/20\n",
      "163/163 [==============================] - 118s 721ms/step - loss: 0.4331 - acc: 0.8204 - val_loss: 0.6507 - val_acc: 0.7500\n",
      "Epoch 2/20\n",
      "103/163 [=================>............] - ETA: 42s - loss: 0.3144 - acc: 0.8783"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "print(\"STARTED at :\", start)\n",
    "history = model.fit_generator(xraydata.train_generator, \n",
    "                                steps_per_epoch = len(xraydata.train_generator),\n",
    "                                epochs = 20,\n",
    "                                verbose = 1,\n",
    "                                workers = 20,\n",
    "                                validation_data = xraydata.valid_generator, \n",
    "                                validation_steps = len(xraydata.valid_generator),\n",
    "                                class_weight = xraydata.train_class_weights)\n",
    "end = datetime.now()\n",
    "print(\"ENDED at\", end)\n",
    "print((end-now).total_seconds() / 60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "xlabel = 'Epoch'\n",
    "legends = ['Training', 'Validation']\n",
    "\n",
    "ylim_pad = [0.01, 0.1]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot training & validation Accuracy values\n",
    "\n",
    "y1 = history.history['acc']\n",
    "y2 = history.history['val_acc']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[0]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[0]\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Accuracy', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "\n",
    "                         \n",
    "# Plot training & validation loss values\n",
    "    \n",
    "y1 = history.history['loss']\n",
    "y2 = history.history['val_loss']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[1]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[1]\n",
    "    \n",
    "    \n",
    "plt.subplot(122)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Loss', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "                         \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = [\"normal\", \"pneumonia\"]\n",
    "for _set in (xraydata.test_generator, xraydata.valid_generator):\n",
    "    y_pred = model.predict_generator(_set,\n",
    "                                     steps = len(_set),\n",
    "                                     verbose = 0)\n",
    "    y_true = xraydata.test_generator.classes\n",
    "    y_pred = y_pred.argmax(axis=-1)\n",
    "    print(classification_report(y, y_pred, target_names = target_names))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import cv2\n",
    "label_dict = {0:\"PNEUMONIA\", 1:\"NORMAL\"}\n",
    "\n",
    "def display_sample()\n",
    "    test_file_names = xraydata.test_generator.filenames\n",
    "    n = len(test_file_names)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = 12, 10\n",
    "\n",
    "    for i in range(2):\n",
    "        index = randint(0, n - 1)\n",
    "        file_name = \"data/input/val/\"+ test_file_names[index]\n",
    "\n",
    "        image = cv2.imread(file_name, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        ground_truth_label = label_dict[int(y[index])]\n",
    "        predicted_label = label_dict[int(y_pred[index])]\n",
    "    \n",
    "        plt.subplot(5, 1, i + 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image)\n",
    "    \n",
    "        title = \"Ground Truth = \" + ground_truth_label + \", Predicted Label = \" + predicted_label\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(CPU)",
   "language": "python",
   "name": "pythoncpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
